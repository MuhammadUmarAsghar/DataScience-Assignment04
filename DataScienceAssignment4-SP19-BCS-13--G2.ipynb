{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math as m\n",
        "import datetime as dt\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "\n",
        "data = pd.read_csv('data.txt', sep=\"\\t\")\n",
        "print(\" Dataset has \" + str(len(data.columns)) + \" columns\" )"
      ],
      "metadata": {
        "id": "steH9898FURV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nulls = data.isnull().sum().sort_values(ascending=False)\n",
        "nulls[nulls > 0]\n",
        "\n",
        "\n",
        "def ex_scale(df, cols):\n",
        "  for col in cols:\n",
        "    df[col] = df[col].map({'Ex': 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Pn\": 1, \"NA\": 0})\n",
        "    df[col] = pd.to_numeric(df[col])\n",
        "    df[col] = df[col].fillna(0)\n",
        "\n",
        "\n",
        "columns = [\"Exter Cond\", 'Exter Qual', 'Bsmt Qual','Bsmt Cond', 'Fireplace Qu', 'Garage Qual', 'Garage Cond', 'Heating QC', 'Kitchen Qual', 'Pool QC']\n",
        "ex_scale(data, columns)\n",
        "\n",
        "\n",
        "\n",
        "def var_scale (column, reassign_dict, data_set = data): \n",
        "\n",
        "  data_set [column] = pd.to_numeric(data_set[column].map(reassign_dict)) \n",
        "  data_set[column] = data_set[column].fillna(0)\n",
        "#print(data_set[column].value_counts().sum())"
      ],
      "metadata": {
        "id": "HUhQQ5N0Fwcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_scale('Lot Shape', {'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0})\n",
        "var_scale('Utilities', {'AllPub': 3, 'NoSewr': 2, 'NoSeWa': 1, 'ELO': 0})\n",
        "var_scale( 'Land Slope', {'Gtl': 2, 'Mod': 1, 'Sev': 0})\n",
        "var_scale('Bsmt Exposure', {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0})\n",
        "var_scale('BsmtFin Type 1', {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0})\n",
        "var_scale('BsmtFin Type 2', {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0})\n",
        "var_scale('Electrical', {'SBrkr': 4, 'FuseA': 3, 'FuseF': 2, 'FuseP': 1, 'Mix': 0})\n",
        "var_scale( 'Functional', {'Typ': 7, 'Minl': 6, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 2, 'Sev': 1, 'NA':0})\n",
        "var_scale( 'Garage Finish', {'Fin': 3, 'Rfn': 2, 'Unf': 1})\n",
        "var_scale('Paved Drive', {'Y': 2, 'P': 1, 'N': 0})\n",
        "var_scale('Fence', {'GdPrv': 4, 'MnPrv': 3, 'GdWo': 2, 'MnWw': 1, 'NA': 0})\n",
        "\n",
        "\n",
        "nulls = data.isnull().sum().sort_values(ascending=False)\n",
        "nulls[nulls > 0]"
      ],
      "metadata": {
        "id": "RbcHKT-hGA0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['Misc Feature', 'Alley', 'Lot Frontage', 'Garage Yr Blt', 'Garage Type'], inplace=True)"
      ],
      "metadata": {
        "id": "SHavRX2LGEvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nulls = data.isnull().sum().sort_values(ascending=False)\n",
        "nulls[nulls > 0]"
      ],
      "metadata": {
        "id": "D3YFSDdbGGzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = data.dropna()"
      ],
      "metadata": {
        "id": "NSUrpBC2GIZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['Lot Frontage', 'Mas Vnr Area', 'Garage Area', 'Garage Cars']:\n",
        "  data_clean[col] = data_clean[col].astype('float64', copy=False)\n",
        "\n",
        "baths = [x for x in data_clean.columns if 'Bath' in x]\n",
        "data_clean['Total Baths'] = data_clean[baths].sum(axis=1)\n",
        "data_clean.drop(['Full Bath', 'Half Bath', 'Bsmt Full Bath', 'Bsmt Half Bath'], axis=1, inplace=True)\n",
        "\n",
        "searchfor = 'Fin', 'RFn'\n",
        "data_clean['Has Finished Garage'] = np.where(data_clean['Garage Finish'].str.contains('|'.join(searchfor)), 1, 0)\n",
        "\n",
        "data_clean['Detached Garage'] = np.where(data_clean['Garage Type'].str.contains('Detchd'), 1, 0)\n",
        "\n",
        "data_clean.drop(['Garage Finish', 'Garage Yr Blt', 'Garage Type',], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "RpcQXp4ZGQDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"gender-prediction.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JZ5MtULaGXM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.gender.value_counts().plot(kind=\"bar\")\n",
        "df.gender.value_counts()"
      ],
      "metadata": {
        "id": "r2AgZ4BrGYHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.gender.replace({'female':0,'male':1},inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KXvOlUriGarf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.beard.replace({'yes':1,'no':0},inplace=True)\n",
        "df.head()df.beard.replace({'yes':1,'no':0},inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LMg9Sfv9GcXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hair_length.replace({'bald':0,'short':1, 'medium':2, 'long': 3},inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DNuaDbUIGeDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.eye_color.replace({'black':0,'gray':1, 'blue':2, 'brown': 3, 'green': 4},inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FcHTWibjGg4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.scarf.replace({'yes':1,'no':0},inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BQoI9QBYGi0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.loc[:,  ~df.columns.isin(['beard', 'eye_color', 'hair_length', 'height', 'scarf', 'weight',\t'shoe_size'])]\n",
        "# y = df.loc[:, df.columns!='beard']\n",
        "# y = y.loc[:, y.columns!='eye_color']\n",
        "# y = y.loc[:, y.columns!='hair_length']\n",
        "# y = y.loc[:, y.columns!='scarf']\n",
        "# y = y.loc[:, y.columns!='height']\n",
        "# y = y.loc[:, y.columns!='weight']\n",
        "# y = y.loc[:, y.columns!='shoe_size']\n",
        "\n",
        "y.head()\n",
        "y.shape"
      ],
      "metadata": {
        "id": "f5AUEHDOGkmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.loc[:, ~df.columns.isin(['gender', 'beard', 'scarf'])]\n",
        "x.head()\n",
        "x.shape\n",
        "# x = x.reshape(X.shape[1:])\n",
        "# x.tranpose()"
      ],
      "metadata": {
        "id": "I_-0eZfYGmrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x)\n",
        "cv.get_feature_names()[:5]\n",
        "# X.transpose()\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()"
      ],
      "metadata": {
        "id": "tB90cDQCGoAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "aNYHOx-vGpnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    MultinomialNB()]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(name,   clf)\n",
        "    clf.fit(x_train, y_train)\n",
        "    score = clf.score(x_test, y_test)\n",
        "    print(\"Validation Accuracy\",score*100,\"%\")"
      ],
      "metadata": {
        "id": "AlQb53x2GrDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "uZtoj9zmGuuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    MultinomialNB()]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(name,   clf)\n",
        "    clf.fit(x_train, y_train)\n",
        "    score = clf.score(x_test, y_test)\n",
        "    print(\"Validation Accuracy\",score*100,\"%\")"
      ],
      "metadata": {
        "id": "jPg__2iBGurV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "dt = xgb.DMatrix(x_train,label=y_train)\n",
        "dv = xgb.DMatrix(x_test,label=y_test)\n",
        "params = {\n",
        "    \"eta\": 0.2,\n",
        "    \"max_depth\": 4,\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"silent\": 1,\n",
        "    \"base_score\": np.mean(y_train),\n",
        "    'n_estimators': 1000,\n",
        "    \"eval_metric\": \"logloss\"\n",
        "}\n",
        "model = xgb.train(params, dt, 2000, [(dt, \"train\"),(dv, \"valid\")], verbose_eval=200)\n",
        "y_pred = model.predict(dv)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, (y_pred>0.5))\n",
        "print(cm)\n",
        "# Calculate the accuracy on test set\n",
        "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
        "ax = sns.heatmap(cm, linewidth=0.5)\n",
        "plt.show()\n",
        "print(\"xgboost Acc : \", predict_accuracy_on_test_set)"
      ],
      "metadata": {
        "id": "ghUkwN2DGulk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JrZ2Jm6gGufz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = list(zip(df['height'], df['weight'], df['beard'], df['hair_length'], df['shoe_size'], df['scarf'], df['eye_color']))\n",
        "y = df['gender']\n",
        "output = label_encoded.fit_transform(y)\n",
        "\n",
        "monte_carlo = ShuffleSplit(n_splits=6,test_size=0.33,random_state=3)\n",
        "decision_tree = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "4fshpF2XqBmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_accuracy = cross_val_score(decision_tree,input,target,cv=monte_carlo).mean() * 100\n",
        "mc_f1 = cross_val_score(decision_tree,input,target, scoring=\"f1\", cv=monte_carlo).mean() * 100\n",
        "print(\"Accuracy: \", mc_accuracy, \"%\")\n",
        "print(\"F1 score: \", mc_f1, \"%\")"
      ],
      "metadata": {
        "id": "QuyIq3mjqUk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Leave P-Out cross-validation\n",
        "lpo = LeavePOut(4)\n",
        "lpo.get_n_splits(input)"
      ],
      "metadata": {
        "id": "HcckG3y9qWK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lpo_accuracy = cross_val_score(decision_tree,input,target,cv=lpo).mean() *100\n",
        "lpo_f1 = cross_val_score(decision_tree,input,target,cv=lpo, scoring=\"f1_weighted\").mean() * 100\n",
        "print(\"Accuracy: \", lpo_accuracy, \"%\")\n",
        "print(\"F1 score: \", lpo_f1, \"%\")"
      ],
      "metadata": {
        "id": "zu2N3z34qYw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('gender-prediction_updated.csv')\n",
        "df2"
      ],
      "metadata": {
        "id": "oQtRIHu8qxfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df2.iloc[:80]\n",
        "train_data\n",
        "\n",
        "test_data = df2.iloc[80:]\n",
        "test_data"
      ],
      "metadata": {
        "id": "6ZrZBlu2rOAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = preprocessing.LabelEncoder()\n",
        "\n",
        "df['beard'] = label.fit_transform(df['beard'])\n",
        "df['hair_length'] = label.fit_transform(df['hair_length'])\n",
        "df['scarf'] = label.fit_transform(df['scarf'])\n",
        "df['eye_color'] = label.fit_transform(df['eye_color'])\n",
        "\n",
        "input = list(zip(df['height'], df['weight'], df['beard'], df['hair_length'], df['shoe_size'], df['scarf'], df['eye_color']))\n",
        "target = train_data['gender']"
      ],
      "metadata": {
        "id": "KTqtyN8XqyKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb_prediction = gnb.predict(input)\n",
        "\n",
        "gnb_acc = accuracy_score(target, gnb_prediction)*100\n",
        "gnb_prec = precision_score(target, gnb_prediction, average=None).mean() *100\n",
        "gnb_re = recall_score(target, gnb_prediction, average=None).mean() *100\n",
        "print(\"Accuracy: \", gnb_accuracy, \"%\")\n",
        "print(\"Precision: \", gnb_precision, \"%\")\n",
        "print(\"Recall: \", gnb_recall, \"%\")"
      ],
      "metadata": {
        "id": "7mWB0t1PqyV0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}